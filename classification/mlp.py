# -*- coding: utf-8 -*-
"""MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zFKw0hBFiKs7YmuUKwElgA7PFT1mN9h2
"""

!pip install torchaudio

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
plt.style.use('seaborn-white')
import os

import librosa
import librosa.display
import torch
import torchaudio
import IPython.display as ipd

filename = "/content/drive/MyDrive/Test/audio/fold1/101415-3-0-2.wav"
audio, sr = librosa.load(filename) # 알아서 모노로 바꿔준다, 자동 resampling, 정규화

print(audio) # 소리 세기
print(len(audio))
print('Sampling rate (Hz): %d' %sr)
print('Audio length (seconds): %.2f' % (len(audio) / sr))

ipd.Audio(audio, rate=sr)

plt.figure(figsize =(12,4))
librosa.display.waveplot(y=audio,sr=sr)
plt.show()

metadata = pd.read_csv("/content/drive/MyDrive/Test/UrbanSound8K.csv")
metadata.head()
print(len(metadata))

"""# MFCC"""

mfccs = librosa.feature.mfcc(y=audio, sr=sr)
print(mfccs.shape)

plt.figure(figsize=(14,6))
librosa.display.specshow(mfccs, sr=sr, x_axis='time')

max_pad_len = 1287

def extract_mfcc(file_name):
    try:
        audio, sr = librosa.load(file_name, res_type='kaiser_fast') 
        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)
        #print(mfccs.shape)
        mfccs = np.mean(mfccs.T,axis=0)
    except Exception as e:
        print("Error encountered while parsing file: ", file_name)
        return None 
     
    return mfccs

sample=[]
sample.append(extract_mfcc(filename))

np.shape(sample)

datasetpath = "/content/drive/MyDrive/Test/audio"
audio_mfcc = []

print(len(audio_mfcc))

for index, row in metadata.iterrows():
  file_name = os.path.join(os.path.abspath(datasetpath), 'fold'+str(row["fold"])+'/',str(row["slice_file_name"]))
  class_label = row["classID"]
  data = extract_mfcc(file_name)
  audio_mfcc.append([data, class_label])

mfccresult = pd.DataFrame(audio_mfcc, columns=['mfccs','classID'])

mfccresult.head()

"""# 데이터셋 생성"""

from keras.utils import to_categorical

X = np.array(mfccresult.mfccs.tolist())
y = np.array(mfccresult.classID.tolist())

X.shape

# 원핫 인코딩
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
yy = to_categorical(le.fit_transform(y))

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, yy, test_size = 0.2, random_state = 42)

import tensorflow as tf

num_rows = 40
num_columns = 1287
num_channels = 1

print("train data shape")
print(X_train.shape)
print(X_test.shape)

print(len(X_test))

X_test.shape

num_labels = yy.shape[1]

"""# MLP"""

import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.optimizers import Adam
from keras.utils import np_utils
from sklearn import metrics 

num_labels = yy.shape[1]
filter_size = 2

# Construct model 
model = Sequential()

model.add(Dense(256, input_shape=(40,)))
model.add(Activation('relu'))
model.add(Dropout(0.5))

model.add(Dense(256))
model.add(Activation('relu'))
model.add(Dropout(0.5))

model.add(Dense(num_labels))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')
model.summary()

score = model.evaluate(X_test, y_test, verbose=0)
accuracy = 100*score[1]

print("Pre-training accuracy: %.4f%%" % accuracy)

model.save('/content/drive/MyDrive/Test/save_models/weights.best.basic_mlp.hdf5')

from keras.callbacks import ModelCheckpoint 
from datetime import datetime 

num_epochs = 300
num_batch_size = 32

checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/Test/save_models/weights.best.basic_mlp.hdf5', verbose=1, save_best_only=True)
start = datetime.now() 

model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)


duration = datetime.now() - start
print("Training completed in time: ", duration)

"""# Evaluating"""

score = model.evaluate(X_train, y_train, verbose=0)
print("Training Accuracy: ", score[1])

score = model.evaluate(X_test, y_test, verbose=0)
print("Testing Accuracy: ", score[1])

